{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e9c80d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:52:45.268007Z",
     "start_time": "2023-11-10T15:52:43.141030Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\User\\Desktop\\Mangimind Data Science Bootcamp\\Sarcopenia_Project\\Sarco_X_JAN_15_2023-patients.xlsx\", sheet_name=\"Sarco_X_Nov_12_2022\")\n",
    "df = df.drop([0], axis=1)\n",
    "df.columns = df.columns.str.replace(' ', '') \n",
    "df.update(df.select_dtypes(include=[np.number]).fillna(0))\n",
    "df.replace(to_replace=[None], value=np.nan, inplace=True)\n",
    "\n",
    "df['DMdrug'].fillna('none', inplace=True)\n",
    "df['Statin'].fillna('none', inplace=True)\n",
    "df['OP'].fillna('none', inplace=True)\n",
    "df['OTHERS'].fillna('none', inplace=True)\n",
    "df['Type_HT'].fillna('none', inplace=True)\n",
    "df['HTdrugs'].fillna('none', inplace=True)\n",
    "df['Education'].fillna('none', inplace=True)\n",
    "df['Job'].fillna('unknown', inplace=True)\n",
    "df['Status'].fillna('unknown', inplace=True)\n",
    "df['Egz'].fillna('none', inplace=True)\n",
    "df['Ad'].fillna('none', inplace=True)\n",
    "\n",
    "df['Alcohol'] = df['Alcohol'].replace(0, 'none')\n",
    "df['Alcohol'] = df['Alcohol'].replace('düzenli içici', 'regular drinker')\n",
    "df['Alcohol'] = df['Alcohol'].replace('Social', 'social drinker')\n",
    "df['Alcohol'] = df['Alcohol'].replace('social', 'social drinker')\n",
    "df['Alcohol'] = df['Alcohol'].replace('Regular', 'regular drinker')\n",
    "df['Alcohol'] = df['Alcohol'].replace('regular', 'regular drinker')\n",
    "\n",
    "df['Statin'] = df['Statin'].replace('atorvastatine', 'atorvastatin')\n",
    "df['Statin'] = df['Statin'].replace('rosuvastatine', 'rosuvastatin')\n",
    "df['Statin'] = df['Statin'].replace('pitavastatine', 'pitavastatin')\n",
    "df['Statin'] = df['Statin'].replace('rosuvastatim', 'rosuvastatin')\n",
    "df['Statin'] = df['Statin'].replace('atorvastatin ', 'atorvastatin')\n",
    "df['Statin'] = df['Statin'].replace('pitovastatin', 'pitavastatin')\n",
    "df['Statin'] = df['Statin'].replace('atorvastatin', 'atorvastatin')\n",
    "\n",
    "df['Education'] = df['Education'].replace('üniversity', 'university')\n",
    "df['Education'] = df['Education'].replace('primary shool', 'primary school')\n",
    "df['Education'] = df['Education'].replace('illiterate', 'none')\n",
    "\n",
    "df['Status'] = df['Status'].replace('full time', 'full-time worker')\n",
    "df['Status'] = df['Status'].replace('part time work', 'part-time worker')\n",
    "df['Status'] = df['Status'].replace('full/part time worker', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('ull-time/part-time work', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('retiret', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('emekli', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('evhanımı', 'housewife')\n",
    "df['Status'] = df['Status'].replace('retire', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('full time work', 'full-time worker')\n",
    "df['Status'] = df['Status'].replace('full/part time work', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('full/part time', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('full-time', 'full-time worker')\n",
    "df['Status'] = df['Status'].replace('emekli veya çalışmıyor', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('tam/kısmi zamanlı çalışıyor', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('workşng', 'actively working')\n",
    "df['Status'] = df['Status'].replace('çalişiyor', 'actively working')\n",
    "df['Status'] = df['Status'].replace('not working', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('calısıyor', 'actively working')\n",
    "df['Status'] = df['Status'].replace('çalışmıyor', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('tam/kısmi zamnalı çalışıyor', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('kısmi çalışıyor', 'part-time worker')\n",
    "df['Status'] = df['Status'].replace('çalışıyor', 'actively working')\n",
    "df['Status'] = df['Status'].replace('kısmi', 'part-time worker')\n",
    "df['Status'] = df['Status'].replace('tam zamanlı çalışıyor', 'full time work')\n",
    "df['Status'] = df['Status'].replace('emekli vey çalışmıyor', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('çalşimiyor', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('çalişmiyor', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('tam/kismi̇ çalişiyor', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('emekli̇/çalişmiyor', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('emekli̇', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('emekli çalışmıyor', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('tam veya kısmı zamanlı calısıyor', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('retired/nonworking', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('non working', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('çalişmiyorr', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('tam zamanlı', 'full-time worker')\n",
    "df['Status'] = df['Status'].replace('çalışmıuor', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('tam/kısmi zamanlı', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('aktif çalışan', 'actively working')\n",
    "df['Status'] = df['Status'].replace('none', 'unknown')\n",
    "df['Status'] = df['Status'].replace('full time work', 'full-time worker')\n",
    "df['Status'] = df['Status'].replace('full-time/part-time work', 'full-time/part-time worker')\n",
    "df['Status'] = df['Status'].replace('worker', 'working')\n",
    "df['Status'] = df['Status'].replace('retired', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('worker', 'actively working')\n",
    "df['Status'] = df['Status'].replace('working', 'actively working')\n",
    "df['Status'] = df['Status'].replace('abstinence', 'retired or not working')\n",
    "df['Status'] = df['Status'].replace('unemployednone', 'unknown')\n",
    "\n",
    "df['Egz'] = df['Egz'].replace(0, 'none')\n",
    "df['Egz'] = df['Egz'].replace(' 1-2/week', '1-2/week')\n",
    "\n",
    "df['Sarcopenia'] = df['Sarcopenia'].replace(0, 'Sarcopenia - NO')\n",
    "df['Sarcopenia'] = df['Sarcopenia'].replace(1, 'Sarcopenia - YES')\n",
    "df['Sarcopenia'] = df['Sarcopenia'].astype('str')\n",
    "\n",
    "df['Age'] = df['Age'].astype('int64')\n",
    "\n",
    "df['Smoking'] = df['Smoking'].replace(0, 'Smoking - NO')\n",
    "df['Smoking'] = df['Smoking'].replace(1, 'Smoking - YES')\n",
    "df['Smoking'] = df['Smoking'].astype('str')\n",
    "\n",
    "df['Smoking(packet/year)'] = df['Smoking(packet/year)'].astype('int64')\n",
    "\n",
    "df['DM'] = df['DM'].astype('int64')\n",
    "df['DM'] = df['DM'].replace(0, 'Diabetes mellitus - NO')\n",
    "df['DM'] = df['DM'].replace(1, 'Diabetes mellitus - YES')\n",
    "df['DM'] = df['DM'].astype('str')\n",
    "\n",
    "df['DMduration'] = df['DMduration'].astype('int64')\n",
    "\n",
    "df = df.rename(columns={'İnsülin': 'Insulin'})\n",
    "df['Insulin'] = df['Insulin'].replace(0, 'Insulin - NO')\n",
    "df['Insulin'] = df['Insulin'].replace(1, 'Insulin - YES')\n",
    "df['Insulin'] = df['Insulin'].astype('str')\n",
    "\n",
    "df['Hipotiroidi'] = df['Hipotiroidi'].replace(0, 'Hipotiroidi - NO')\n",
    "df['Hipotiroidi'] = df['Hipotiroidi'].replace(1, 'Hipotiroidi - YES')\n",
    "df['Hipotiroidi'] = df['Hipotiroidi'].astype('str')\n",
    "\n",
    "df['ASTIM'] = df['ASTIM'].replace(0, 'ASTIM - NO')\n",
    "df['ASTIM'] = df['ASTIM'].replace(1, 'ASTIM - YES')\n",
    "df['ASTIM'] = df['ASTIM'].astype('str')\n",
    "\n",
    "df['OP'] = df['OP'].replace(0, 'OP - NO')\n",
    "df['OP'] = df['OP'].replace(1, 'OP - YES')\n",
    "df['OP'] = df['OP'].replace('none', 'OP - NO')\n",
    "df['OP'] = df['OP'].replace(' ', 'OP - NO')\n",
    "df['OP'] = df['OP'].astype('str')\n",
    "\n",
    "df['HT'] = df['HT'].astype('int64')\n",
    "df['HT'] = df['HT'].replace(0, 'Hormone therapy - NO')\n",
    "df['HT'] = df['HT'].replace(1, 'Hormone therapy - YES')\n",
    "\n",
    "df = df.rename(columns={'DırationofHT': 'Duration_of_HT'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e485d2c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:52:45.284021Z",
     "start_time": "2023-11-10T15:52:45.269008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5016 entries, 0 to 5015\n",
      "Data columns (total 42 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   MMSE                  5016 non-null   float64\n",
      " 1   Age                   5016 non-null   int64  \n",
      " 2   Weight                5016 non-null   float64\n",
      " 3   Height                5016 non-null   float64\n",
      " 4   Waist                 5016 non-null   float64\n",
      " 5   Hip                   5016 non-null   float64\n",
      " 6   Smoking               5016 non-null   object \n",
      " 7   Smoking(packet/year)  5016 non-null   int64  \n",
      " 8   Alcohol               5016 non-null   object \n",
      " 9   DM                    5016 non-null   object \n",
      " 10  DMduration            5016 non-null   int64  \n",
      " 11  Insulin               5016 non-null   object \n",
      " 12  DMdrug                5016 non-null   object \n",
      " 13  Dyslipidemia          5016 non-null   int64  \n",
      " 14  Dyslipidemiaduration  5016 non-null   float64\n",
      " 15  Statin                5016 non-null   object \n",
      " 16  KAH                   5016 non-null   int64  \n",
      " 17  KAHduration           5016 non-null   float64\n",
      " 18  Hipotiroidi           5016 non-null   object \n",
      " 19  ASTIM                 5016 non-null   object \n",
      " 20  KOAH                  5016 non-null   int64  \n",
      " 21  OP                    5016 non-null   object \n",
      " 22  OTHERS                5016 non-null   object \n",
      " 23  HT                    5016 non-null   object \n",
      " 24  Type_HT               5016 non-null   object \n",
      " 25  Duration_of_HT        5016 non-null   float64\n",
      " 26  N_HT                  5016 non-null   float64\n",
      " 27  HTdrugs               5016 non-null   object \n",
      " 28  Durationof1HT         5016 non-null   float64\n",
      " 29  Education             5016 non-null   object \n",
      " 30  Job                   5016 non-null   object \n",
      " 31  Status                5016 non-null   object \n",
      " 32  Egz                   5016 non-null   object \n",
      " 33  AT                    5016 non-null   float64\n",
      " 34  CST                   5016 non-null   float64\n",
      " 35  GS                    5016 non-null   float64\n",
      " 36  GS.1                  5016 non-null   float64\n",
      " 37  Star                  5016 non-null   float64\n",
      " 38  BMI                   5016 non-null   float64\n",
      " 39  Sarcopenia            5016 non-null   object \n",
      " 40  Gender                5016 non-null   object \n",
      " 41  Ad                    5016 non-null   object \n",
      "dtypes: float64(16), int64(6), object(20)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4555fe83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:52:45.843089Z",
     "start_time": "2023-11-10T15:52:45.286023Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Convert all categorical columns to string type\n",
    "df[categorical_cols] = df[categorical_cols].astype(str)\n",
    "\n",
    "# Initialize one-hot encoder\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "\n",
    "# Encode the categorical columns\n",
    "encoded_array = encoder.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Generate column names for encoded columns\n",
    "column_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Create a dataframe from the encoded array\n",
    "df_encoded = pd.DataFrame(encoded_array, columns=column_names)\n",
    "\n",
    "# Drop original categorical columns from df\n",
    "df.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "# Concatenate the original dataframe with the encoded dataframe\n",
    "df = pd.concat([df, df_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235713da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:52:46.017210Z",
     "start_time": "2023-11-10T15:52:45.844090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5016 entries, 0 to 5015\n",
      "Columns: 2824 entries, MMSE to Ad_ÖZDEN\n",
      "dtypes: float64(2818), int64(6)\n",
      "memory usage: 108.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e94ffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:53:10.923716Z",
     "start_time": "2023-11-10T15:52:46.018211Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 6.8056 - accuracy: 0.8439 - val_loss: 3.8636 - val_accuracy: 0.7408\n",
      "Epoch 2/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 2.5529 - accuracy: 0.8586 - val_loss: 1.9144 - val_accuracy: 0.6949\n",
      "Epoch 3/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 1.3744 - accuracy: 0.8646 - val_loss: 1.2522 - val_accuracy: 0.7677\n",
      "Epoch 4/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.9792 - accuracy: 0.8712 - val_loss: 0.9437 - val_accuracy: 0.8405\n",
      "Epoch 5/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.8267 - accuracy: 0.8718 - val_loss: 0.7955 - val_accuracy: 0.8245\n",
      "Epoch 6/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.8755 - val_loss: 0.7303 - val_accuracy: 0.8285\n",
      "Epoch 7/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.8838 - val_loss: 0.6137 - val_accuracy: 0.8395\n",
      "Epoch 8/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.8842 - val_loss: 0.5509 - val_accuracy: 0.8245\n",
      "Epoch 9/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8859 - val_loss: 0.5063 - val_accuracy: 0.8455\n",
      "Epoch 10/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8898 - val_loss: 0.4427 - val_accuracy: 0.8514\n",
      "Epoch 11/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8879 - val_loss: 0.4541 - val_accuracy: 0.8485\n",
      "Epoch 12/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8854 - val_loss: 0.4343 - val_accuracy: 0.8405\n",
      "Epoch 13/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8912 - val_loss: 0.4524 - val_accuracy: 0.8475\n",
      "Epoch 14/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8869 - val_loss: 0.4213 - val_accuracy: 0.8485\n",
      "Epoch 15/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8896 - val_loss: 0.4368 - val_accuracy: 0.8435\n",
      "Epoch 16/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8919 - val_loss: 0.3987 - val_accuracy: 0.8495\n",
      "Epoch 17/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8885 - val_loss: 0.4200 - val_accuracy: 0.8534\n",
      "Epoch 18/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8960 - val_loss: 0.3817 - val_accuracy: 0.8514\n",
      "Epoch 19/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8896 - val_loss: 0.4477 - val_accuracy: 0.8485\n",
      "Epoch 20/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8912 - val_loss: 0.3915 - val_accuracy: 0.8514\n",
      "Epoch 21/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8807 - val_loss: 0.4207 - val_accuracy: 0.8514\n",
      "Epoch 22/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8869 - val_loss: 0.4386 - val_accuracy: 0.8385\n",
      "Epoch 23/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8916 - val_loss: 0.4190 - val_accuracy: 0.8524\n",
      "Epoch 24/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8902 - val_loss: 0.4027 - val_accuracy: 0.8445\n",
      "Epoch 25/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8892 - val_loss: 0.3939 - val_accuracy: 0.8415\n",
      "Epoch 26/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8931 - val_loss: 0.4197 - val_accuracy: 0.8465\n",
      "Epoch 27/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8846 - val_loss: 0.3770 - val_accuracy: 0.8524\n",
      "Epoch 28/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8923 - val_loss: 0.3775 - val_accuracy: 0.8475\n",
      "Epoch 29/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8914 - val_loss: 0.4197 - val_accuracy: 0.8445\n",
      "Epoch 30/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8933 - val_loss: 0.3861 - val_accuracy: 0.8445\n",
      "Epoch 31/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8929 - val_loss: 0.4402 - val_accuracy: 0.8315\n",
      "Epoch 32/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8952 - val_loss: 0.4057 - val_accuracy: 0.8425\n",
      "Epoch 33/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8931 - val_loss: 0.4000 - val_accuracy: 0.8435\n",
      "Epoch 34/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8910 - val_loss: 0.4264 - val_accuracy: 0.8504\n",
      "Epoch 35/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8921 - val_loss: 0.4171 - val_accuracy: 0.8405\n",
      "Epoch 36/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8956 - val_loss: 0.4342 - val_accuracy: 0.8495\n",
      "Epoch 37/80\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8943 - val_loss: 0.3851 - val_accuracy: 0.8465\n",
      "Test Accuracy: 0.8705\n",
      "Epoch 1: Validation Loss: 3.8636, Validation Accuracy: 0.7408\n",
      "Epoch 2: Validation Loss: 1.9144, Validation Accuracy: 0.6949\n",
      "Epoch 3: Validation Loss: 1.2522, Validation Accuracy: 0.7677\n",
      "Epoch 4: Validation Loss: 0.9437, Validation Accuracy: 0.8405\n",
      "Epoch 5: Validation Loss: 0.7955, Validation Accuracy: 0.8245\n",
      "Epoch 6: Validation Loss: 0.7303, Validation Accuracy: 0.8285\n",
      "Epoch 7: Validation Loss: 0.6137, Validation Accuracy: 0.8395\n",
      "Epoch 8: Validation Loss: 0.5509, Validation Accuracy: 0.8245\n",
      "Epoch 9: Validation Loss: 0.5063, Validation Accuracy: 0.8455\n",
      "Epoch 10: Validation Loss: 0.4427, Validation Accuracy: 0.8514\n",
      "Epoch 11: Validation Loss: 0.4541, Validation Accuracy: 0.8485\n",
      "Epoch 12: Validation Loss: 0.4343, Validation Accuracy: 0.8405\n",
      "Epoch 13: Validation Loss: 0.4524, Validation Accuracy: 0.8475\n",
      "Epoch 14: Validation Loss: 0.4213, Validation Accuracy: 0.8485\n",
      "Epoch 15: Validation Loss: 0.4368, Validation Accuracy: 0.8435\n",
      "Epoch 16: Validation Loss: 0.3987, Validation Accuracy: 0.8495\n",
      "Epoch 17: Validation Loss: 0.4200, Validation Accuracy: 0.8534\n",
      "Epoch 18: Validation Loss: 0.3817, Validation Accuracy: 0.8514\n",
      "Epoch 19: Validation Loss: 0.4477, Validation Accuracy: 0.8485\n",
      "Epoch 20: Validation Loss: 0.3915, Validation Accuracy: 0.8514\n",
      "Epoch 21: Validation Loss: 0.4207, Validation Accuracy: 0.8514\n",
      "Epoch 22: Validation Loss: 0.4386, Validation Accuracy: 0.8385\n",
      "Epoch 23: Validation Loss: 0.4190, Validation Accuracy: 0.8524\n",
      "Epoch 24: Validation Loss: 0.4027, Validation Accuracy: 0.8445\n",
      "Epoch 25: Validation Loss: 0.3939, Validation Accuracy: 0.8415\n",
      "Epoch 26: Validation Loss: 0.4197, Validation Accuracy: 0.8465\n",
      "Epoch 27: Validation Loss: 0.3770, Validation Accuracy: 0.8524\n",
      "Epoch 28: Validation Loss: 0.3775, Validation Accuracy: 0.8475\n",
      "Epoch 29: Validation Loss: 0.4197, Validation Accuracy: 0.8445\n",
      "Epoch 30: Validation Loss: 0.3861, Validation Accuracy: 0.8445\n",
      "Epoch 31: Validation Loss: 0.4402, Validation Accuracy: 0.8315\n",
      "Epoch 32: Validation Loss: 0.4057, Validation Accuracy: 0.8425\n",
      "Epoch 33: Validation Loss: 0.4000, Validation Accuracy: 0.8435\n",
      "Epoch 34: Validation Loss: 0.4264, Validation Accuracy: 0.8504\n",
      "Epoch 35: Validation Loss: 0.4171, Validation Accuracy: 0.8405\n",
      "Epoch 36: Validation Loss: 0.4342, Validation Accuracy: 0.8495\n",
      "Epoch 37: Validation Loss: 0.3851, Validation Accuracy: 0.8465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# Assuming df is your DataFrame and 'Sarcopenia_Sarcopenia - YES' is your target column\n",
    "X = df.drop(['Sarcopenia_Sarcopenia - YES', 'CST', 'GS.1'], axis=1)  # Features\n",
    "y = df['Sarcopenia_Sarcopenia - YES'] \n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(sampling_strategy='auto')\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature selection using XGBoost (now on resampled data)\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_resampled, y_train_resampled)  # Fit on resampled data\n",
    "selector = SelectFromModel(xgb, prefit=True, max_features=5)\n",
    "\n",
    "# Apply feature selection to the resampled and other datasets\n",
    "X_train_selected = selector.transform(X_train_resampled)  # Apply to resampled data\n",
    "X_val_selected = selector.transform(X_val)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the corresponding feature names\n",
    "selected_feature_names = [feature_names[i] for i in selected_feature_indices]\n",
    "\n",
    "# Define PCA with the best parameters\n",
    "pca = PCA(n_components=0.99, svd_solver='full', iterated_power='auto', tol=0.0, whiten=False)\n",
    "\n",
    "# Apply PCA to all datasets\n",
    "X_train_pca = pca.fit_transform(X_train_selected)\n",
    "X_val_pca = pca.transform(X_val_selected)\n",
    "X_test_pca = pca.transform(X_test_selected)\n",
    "\n",
    "# Scaling should be fit on the transformed train data and then applied to the validation and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)  # Fit and transform on train data\n",
    "X_val_scaled = scaler.transform(X_val_selected)  # Transform validation data\n",
    "X_test_scaled = scaler.transform(X_test_selected)  # Transform test data\n",
    "\n",
    "\n",
    "# Define the model creation function with the best parameters\n",
    "def create_model(input_shape, learning_rate=0.001, neurons1=300, neurons2=600, dropout_rate=0.5, l1=0.001, l2=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons1, activation='relu', kernel_regularizer=l1_l2(l1=l1, l2=l2), input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='relu', kernel_regularizer=l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer_instance = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer_instance, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the Keras model with the correct input shape and learning rate\n",
    "input_shape = (X_train_scaled.shape[1],)  # Specify the input shape here\n",
    "model = create_model(input_shape=input_shape, learning_rate=0.001)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Fit the model with training data (resampled and processed) and validation data\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_resampled, \n",
    "    batch_size=32,\n",
    "    epochs=80,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)[1]\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Access validation loss and accuracy from the model history\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Print validation loss and accuracy\n",
    "for epoch, (loss, accuracy) in enumerate(zip(val_loss, val_accuracy), 1):\n",
    "    print(f'Epoch {epoch}: Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "model.save('best_model_with_selected_features.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e8badc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:53:11.081864Z",
     "start_time": "2023-11-10T15:53:10.924720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 807us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.85      0.91       768\n",
      "         1.0       0.66      0.94      0.77       236\n",
      "\n",
      "    accuracy                           0.87      1004\n",
      "   macro avg       0.82      0.89      0.84      1004\n",
      "weighted avg       0.90      0.87      0.88      1004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predictions on the test dataset\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert predicted probabilities to binary labels (0 or 1)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a99b9fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:53:11.176982Z",
     "start_time": "2023-11-10T15:53:11.082867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 807us/step\n",
      "True Positives (TP): 222\n",
      "False Positives (FP): 116\n",
      "False Negatives (FN): 14\n",
      "True Negatives (TN): 652\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on the test dataset\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert predicted probabilities to binary labels (0 or 1)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate TP, FP, FN, and TN\n",
    "TP = ((y_test == 1) & (y_pred == 1)).sum()\n",
    "FP = ((y_test == 0) & (y_pred == 1)).sum()\n",
    "FN = ((y_test == 1) & (y_pred == 0)).sum()\n",
    "TN = ((y_test == 0) & (y_pred == 0)).sum()\n",
    "\n",
    "# Print the counts\n",
    "print(f'True Positives (TP): {TP}')\n",
    "print(f'False Positives (FP): {FP}')\n",
    "print(f'False Negatives (FN): {FN}')\n",
    "print(f'True Negatives (TN): {TN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf40864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
